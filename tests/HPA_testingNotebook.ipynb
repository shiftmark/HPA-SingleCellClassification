{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uA2kroxdDIhF",
    "outputId": "2660eb09-b4cd-43d7-aed4-102f61e6943e"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/shiftmark/HPA-SingleCellClassification.git\n",
    "#!git clone https://github.com/CellProfiling/HPA-Cell-Segmentation.git\n",
    "#!cd HPA-Cell-Segmentation && sh install.sh\n",
    "#!pip uninstall PIL && pip uninstall Pillow -y && pip install Pillow\n",
    "# restart for Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AOxohn2_hQMy",
    "outputId": "2bbb16d4-e9e1-42a4-89b9-e5eb2e5cb230"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.insert(0, '../src/')\n",
    "sys.path.insert(0, '../tests/')\n",
    "\n",
    "from utils.download_files import DownloadFile\n",
    "from utils.create_tfrecord import CreateTFRecord\n",
    "from utils.parse_example import ParseExample\n",
    "from train.helpers import plot_images, plot_history\n",
    "from train.augment import Augment\n",
    "from train.get_model import GetModel\n",
    "import train.constants as c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gE4Hi0hPBb9d"
   },
   "outputs": [],
   "source": [
    "dg.download(8, SAVE_IMG_TO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = c.DF\n",
    "# Create a pd.Series with one-hot encoded values and merge it with dataframe\n",
    "df =df.merge(pd.Series(c.DF.Label_idx).str.get_dummies(), right_index=True, left_on=df.index)\n",
    "# Keep just 'Image', '0', '1', ..., '18' columns\n",
    "df.drop(['key_0', 'Label', 'Cellline', 'in_trainset', 'Label_idx'], inplace=True, axis=1)\n",
    "# Create column 'Name' for image names\n",
    "df['Name'] = df.Image.map(lambda x: x.split('/')[-1])\n",
    "# Create 'Labels' column, containing one-hot encoded arrays\n",
    "df['Labels'] = df[[str(s) for s in range(19)]].apply(lambda x: list(x), axis=1)\n",
    "# Drop '0', '1', ..., '18' columns\n",
    "df.drop([str(s) for s in range(19)], axis=1, inplace=True)\n",
    "# Set 'Name' as index\n",
    "df.set_index('Name', inplace=True)\n"
   ]
  },
  {
   "source": [
    "CreateTFRecord(c.MULTICHANNEL_IMGS, df).write_to(c.SAVE_TFREC_TO, num_items_in_record=13)"
   ],
   "cell_type": "code",
   "metadata": {
    "id": "NKrM78wGIg10"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-vLLoRo3yc1L",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'SAVE_TFREC_TO' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e565db88cc67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{SAVE_TFREC_TO}/*.tfrec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SAVE_TFREC_TO' is not defined"
     ]
    }
   ],
   "source": [
    "imgs = []\n",
    "filenames = glob.glob(f'{SAVE_TFREC_TO}/*.tfrec')\n",
    "dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "for i in dataset.take(6):\n",
    "    \n",
    "    imgs.append(ParseExample(i, return_img_name=True).parse_eg()[1])\n",
    "    \n",
    "data = tf.data.Dataset.from_tensors(imgs)\n",
    "data2 = Augment(flip_horizontal=False,\n",
    "                seed=tf.random.uniform((2,),maxval=9, dtype=tf.int32),\n",
    "                contrast={'lower':.1, 'upper':.9},\n",
    "                brightness={'max_delta':.1},\n",
    "                saturation={'lower':.2, 'upper':.7}\n",
    "                ).apply_on(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "IiAdFZ1vIBFc",
    "outputId": "a166da04-7090-4293-d20e-480d2371e4aa"
   },
   "outputs": [],
   "source": [
    "plot_images(imgs, show_axes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9s_h4QIhQWI"
   },
   "outputs": [],
   "source": [
    "model = GetModel().set_backbone(\"EfficientNetB0\", input_shape=(224,224,3), include_top=True)\n",
    "model = tf.keras.Model(inputs=model.inputs, outputs=model.outputs)\n",
    "#model.summary()\n",
    "\n",
    "\n",
    "model2 = GetModel().set_backbone(\"EfficientNetB7\", input_shape=(600,600,3), include_top=False).add_top(23,.4,33)\n",
    "\n",
    "#model = Unet((32, 800, 3), 7).unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7pe8k39MojPY"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EdXql5I0wDSR"
   },
   "outputs": [],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jDoGXmftQua"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=5, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.experimental.enable_dump_debug_info(log_dir, tensor_debug_mode=\"FULL_HEALTH\", circular_buffer_size=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "HPA-testingNotebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python382jvsc74a57bd0650b1729ca1100e7d02e4d769428eb66ffe08b4be84b30f9d17918313ba33197",
   "display_name": "Python 3.8.2 64-bit ('code': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "650b1729ca1100e7d02e4d769428eb66ffe08b4be84b30f9d17918313ba33197"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}